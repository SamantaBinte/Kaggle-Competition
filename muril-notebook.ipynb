{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7025229,"sourceType":"datasetVersion","datasetId":4040135}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom torch.optim import SGD\nimport torch.nn as nn\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-11-22T21:24:04.062083Z","iopub.execute_input":"2023-11-22T21:24:04.062442Z","iopub.status.idle":"2023-11-22T21:24:04.068433Z","shell.execute_reply.started":"2023-11-22T21:24:04.062415Z","shell.execute_reply":"2023-11-22T21:24:04.067394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install git+https://github.com/csebuetnlp/normalizer","metadata":{"execution":{"iopub.status.busy":"2023-11-22T21:24:07.778948Z","iopub.execute_input":"2023-11-22T21:24:07.779926Z","iopub.status.idle":"2023-11-22T21:24:21.040545Z","shell.execute_reply.started":"2023-11-22T21:24:07.779888Z","shell.execute_reply":"2023-11-22T21:24:21.039300Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/muril-dataset/cleaned-data2 - Sheet1.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-22T21:24:21.042642Z","iopub.execute_input":"2023-11-22T21:24:21.042979Z","iopub.status.idle":"2023-11-22T21:24:21.308816Z","shell.execute_reply.started":"2023-11-22T21:24:21.042948Z","shell.execute_reply":"2023-11-22T21:24:21.307722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data cleaning\ndef find_substring(input_string):\n    start_word=\"রকমারি\"\n    end_word= \"রিভিউঃ\"\n    start_index = input_string.find(start_word)\n    end_index = input_string.rfind(end_word) + len(end_word)\n    if start_index != -1 and end_index != -1:\n\n        return input_string[end_index:]\n\n    else:\n        return input_string\n\ndf['summary'] = df['summary'].apply(find_substring)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T21:24:28.695849Z","iopub.execute_input":"2023-11-22T21:24:28.696212Z","iopub.status.idle":"2023-11-22T21:24:28.715554Z","shell.execute_reply.started":"2023-11-22T21:24:28.696181Z","shell.execute_reply":"2023-11-22T21:24:28.714622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from normalizer import normalize\n\ndef normalizer_function(input_text):\n  normalized_text = normalize(\n    input_text,\n    unicode_norm=\"NFKC\",          # type of unicode normalization (default \"NFKC\")\n    punct_replacement=None,       # an optional string or callable for replacing the punctuations (default `None`, i.e. no replacement)\n    url_replacement=None,         # an optional string or callable for replacing the URLS (default `None`, i.e. no replacement)\n    emoji_replacement=None,       # an optional string or callable for replacing the emojis (default `None`, i.e. no replacement)\n    apply_unicode_norm_last=True  # whether to apply the unicode normalization before or after rule based replacements (default True)        \n  )\n  return normalized_text\n\ndf['summary'] = df['summary'].apply(normalizer_function)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T21:24:32.490742Z","iopub.execute_input":"2023-11-22T21:24:32.491120Z","iopub.status.idle":"2023-11-22T21:24:48.706880Z","shell.execute_reply.started":"2023-11-22T21:24:32.491091Z","shell.execute_reply":"2023-11-22T21:24:48.705721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into training and validation sets\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(df['summary'], df['Label'], test_size=0.2)\ntrain_labels = train_labels.reset_index(drop=True)\nval_labels = val_labels.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T21:24:54.300908Z","iopub.execute_input":"2023-11-22T21:24:54.301779Z","iopub.status.idle":"2023-11-22T21:24:54.317579Z","shell.execute_reply.started":"2023-11-22T21:24:54.301745Z","shell.execute_reply":"2023-11-22T21:24:54.316770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the MuRIL tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"google/muril-base-cased\", num_labels=7)\n\nmodel = model.to(device)\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    model = torch.nn.DataParallel(model)\n    \n# Tokenize the texts\ntrain_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True)\nval_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True)\n\n# Create a PyTorch Dataset\nclass BanglaSummaryDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create DataLoaders\ntrain_dataset = BanglaSummaryDataset(train_encodings, train_labels)\nval_dataset = BanglaSummaryDataset(val_encodings, val_labels)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T21:24:57.989902Z","iopub.execute_input":"2023-11-22T21:24:57.990406Z","iopub.status.idle":"2023-11-22T21:25:04.391042Z","shell.execute_reply.started":"2023-11-22T21:24:57.990364Z","shell.execute_reply":"2023-11-22T21:25:04.390035Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-11-22T21:25:20.393745Z","iopub.execute_input":"2023-11-22T21:25:20.394154Z","iopub.status.idle":"2023-11-22T21:25:20.399041Z","shell.execute_reply.started":"2023-11-22T21:25:20.394115Z","shell.execute_reply":"2023-11-22T21:25:20.398025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up the optimizer\noptimizer = AdamW(model.parameters(), lr=1e-5)\n\nepochs=50\n\n# Train the model\nfor epoch in range(epochs):\n    model.train()\n    for batch in tqdm(train_loader, desc=\"Training\"):\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss.mean()  # Take the mean of the loss\n        loss.backward()\n        optimizer.step()\n\n#     model.eval()\n#     for batch in tqdm(val_loader, desc=\"Validation\"):\n#         with torch.no_grad():\n#             input_ids = batch['input_ids'].to(device)\n#             attention_mask = batch['attention_mask'].to(device)\n#             labels = batch['labels'].to(device)\n#             outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n#             val_loss = outputs.loss.mean()  # Take the mean of the loss\n    if epoch % 5 == 0:\n        model.eval()\n        y_true = []\n        y_pred = []\n        for batch in tqdm(val_loader, desc=\"Validation\"):\n            with torch.no_grad():\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n                val_loss = outputs.loss.mean()  # Take the mean of the loss\n                logits = outputs.logits.detach().cpu().numpy()\n                predictions = np.argmax(logits, axis=1)\n                y_true.extend(labels.detach().cpu().numpy())\n                y_pred.extend(predictions)\n\n        macro_f1 = f1_score(y_true, y_pred, average='macro')\n        print(f\"Macro F1 score after {epoch+1} epochs: {macro_f1:.4f}\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nimport numpy as np\n\n# Initialize an empty list to save the predictions\npredictions = []\ntrue_labels = []\n\n# Predict\nmodel.eval()\nfor batch in tqdm(val_loader, desc=\"Predicting\"):\n    with torch.no_grad():\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        \n    # Move logits and labels to CPU\n    logits = outputs.logits.detach().cpu().numpy()\n    label_ids = labels.to('cpu').numpy()\n\n    # Store predictions and true labels\n    predictions.append(logits)\n    true_labels.append(label_ids)\n\n# Flatten the outputs\npredictions = np.concatenate(predictions, axis=0)\ntrue_labels = np.concatenate(true_labels, axis=0)\n\n# For each sample, pick the label (0 or 1) with the higher score\npred_flat = np.argmax(predictions, axis=1).flatten()\n\n# Calculate the Macro F1 Score\nmacro_f1 = f1_score(true_labels, pred_flat, average='macro')\n\nprint('Macro F1 Score:', macro_f1)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T23:31:21.071622Z","iopub.execute_input":"2023-11-22T23:31:21.072056Z","iopub.status.idle":"2023-11-22T23:31:34.659151Z","shell.execute_reply.started":"2023-11-22T23:31:21.072025Z","shell.execute_reply":"2023-11-22T23:31:34.658052Z"},"trusted":true},"execution_count":null,"outputs":[]}]}